/**
 * Worker utility for processing frames with vision models.
 * This module handles the background processing of video frames
 * for real-time analysis during recording.
 */

import { createClient } from '@supabase/supabase-js';
import { Database } from '@/lib/db/schema';

// Configure Supabase client
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL || '';
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY || '';
const supabase = createClient<Database>(supabaseUrl, supabaseServiceKey);

// Configure vision API endpoint
const VISION_API_ENDPOINT = process.env.VISION_API_ENDPOINT || 'https://api.openai.com/v1/chat/completions';
const VISION_API_KEY = process.env.VISION_API_KEY || '';

interface FrameProcessingJob {
  asset_id: string;
  frame_url: string;
  captured_at: string;
}

/**
 * Process a single frame with vision model and store results
 * 
 * @param job The frame processing job with metadata
 * @returns Promise that resolves when processing is complete
 */
export async function processFrame(job: FrameProcessingJob): Promise<void> {
  try {
    console.log(`Processing frame for asset ${job.asset_id}: ${job.frame_url}`);
    
    // Call vision API to generate caption
    const caption = await generateCaption(job.frame_url);
    
    // Calculate confidence score (simple implementation)
    const confidence = calculateConfidence(caption);
    
    // Store the results in the database
    await storeFrameResults(job, caption, confidence);
    
    console.log(`Frame processed successfully: ${caption}`);
  } catch (error) {
    console.error('Error processing frame:', error);
    // Don't throw here - we want to continue processing other frames
  }
}

/**
 * Generate a caption for an image using vision model
 * 
 * @param imageUrl URL of the image to analyze
 * @returns Caption generated by the vision model
 */
async function generateCaption(imageUrl: string): Promise<string> {
  // Call the vision model API
  const response = await fetch(VISION_API_ENDPOINT, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${VISION_API_KEY}`
    },
    body: JSON.stringify({
      model: 'gpt-4-vision-preview',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: 'Describe the key elements visible in this frame in a concise sentence.'
            },
            {
              type: 'image_url',
              image_url: {
                url: imageUrl
              }
            }
          ]
        }
      ],
      max_tokens: 100
    })
  });
  
  if (!response.ok) {
    throw new Error(`Vision API error: ${response.status} ${response.statusText}`);
  }
  
  const data = await response.json();
  return data.choices[0].message.content.trim();
}

/**
 * Calculate a confidence score for the caption
 * 
 * @param caption The generated caption
 * @returns Confidence score between 0 and 1
 */
function calculateConfidence(caption: string): number {
  // Simple heuristic - based on length and specificity
  // In a real implementation, this would use more sophisticated metrics
  if (!caption) return 0;
  
  // Penalize very short or very long captions
  const length = caption.length;
  if (length < 10) return 0.3;
  if (length > 200) return 0.5;
  
  // Reward specific details and proper nouns
  const hasSpecifics = /\b(shows|contains|displays|has|with)\b/i.test(caption);
  const hasMeasurement = /\b(\d+|one|two|three|four|five|several|many|few)\b/i.test(caption);
  
  let score = 0.6; // Base score
  if (hasSpecifics) score += 0.1;
  if (hasMeasurement) score += 0.1;
  
  return Math.min(score, 0.95); // Cap at 0.95
}

/**
 * Store frame processing results in the database
 * 
 * @param job The frame processing job
 * @param caption The generated caption
 * @param confidence The confidence score
 */
async function storeFrameResults(
  job: FrameProcessingJob,
  caption: string,
  confidence: number
): Promise<void> {
  const { data, error } = await supabase
    .from('scratch_items')
    .insert({
      asset_id: job.asset_id,
      captured_at: job.captured_at,
      caption: caption,
      image_url: job.frame_url,
      confidence: confidence
    });
  
  if (error) {
    throw new Error(`Failed to store frame results: ${error.message}`);
  }
} 